# Machine LearningTutorial 
Wine Quality Analysis with Decision Trees and Random Forests
Name: Bhavya Sandhu
ID: 23022333
Objective: The objective of this case study is to explore and analyze the Wine Quality dataset using machine learning techniques. It involves tasks such as data loading, preprocessing, exploratory data analysis (EDA), model training, prediction, evaluation, and visualization.It contains a step-by-step tutorial on Decision Trees and Random Forests, focusing on feature importance and overfitting, using the Wine Quality dataset. The tutorial is designed to act as a teaching resource, providing clear explanations, runnable code, and insightful visualizations.

## Features
- Analysis of Decision Trees and Random Forests.
- Demonstration of feature importance.
- Discussion on overfitting and techniques to mitigate it.
- Application of models to predict wine quality.

## Dataset
The tutorial uses the **Wine Quality Dataset**, which contains physicochemical attributes of wines and their quality ratings. The dataset is preprocessed and analyzed within the notebook.

Installation
To replicate this project, ensure you have the following dependencies installed:

Required Libraries
numpy
pandas
matplotlib
scikit-learn
seaborn

How to Run the Code
Clone the repository:  git clone https://github.com/<your-username>/DecisionTrees_WineQuality.git
cd DecisionTrees_WineQuality

## Repository Structure
- `Bhavya_ML_Tutorial_.ipynb`: Google Colab Notebook containing the full tutorial, including code and visualizations.
- `README.md`: Overview of the repository.
- `LICENSE`: Terms of use for this repository.

## Required Libraries
tensorflow
scikit-learn
pandas
matplotlib
seaborn

## How to run the code 
1.Download the repository or clone it using the following command:

2.Open the  Notebook file (creditrisk_nn.ipynb) in your preferred environment, such as Jupyter Notebook, VSCode, or Google Colab.
3.Run the cells step-by-step to:
-Load and preprocess the dataset.
-Experiment with different architectures (depths and widths).
-Visualize results and evaluate performance.

## References
-Breiman, L., 2001. Random Forests. Machine Learning, 45(1), pp.5-32. Available at: https://link.springer.com/article/10.1023/A:1010933404324.

-Dua, D. & Graff, C., 2019. UCI Machine Learning Repository. Available at: https://archive.ics.uci.edu/ml/datasets/wine+quality.

-Kuhn, M. & Johnson, K., 2013. Applied Predictive Modeling. New York: Springer. Available at: https://link.springer.com/book/10.1007/978-1-4614-6849-3.



